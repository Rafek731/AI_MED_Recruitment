{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d37044f",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "In this file we'll se performance of the models shown in ``showcase_of_models.ipynb``.\n",
    "We'll use various evaluation metrics and we'll compare performance of diffrent models on the same datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5f4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "\n",
    "from ML import KNN_classifier, DecisionTree, RandomForest\n",
    "from data_processing import preprocess_data, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e53785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('task_data.csv')\n",
    "data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1837e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models\n",
    "models = [KNN_classifier(k=3, name='KNN3'), \n",
    "          KNN_classifier(k=5, name='KNN5'), \n",
    "          DecisionTree(max_depth=5, name='DecisionTree'), \n",
    "          RandomForest(n_trees=100, max_depth=10, name='RandomForest')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e54f4",
   "metadata": {},
   "source": [
    "### LpO Cross-validation\n",
    "\n",
    "Or *Leave p out Cross-validation* means that each time going over dataset we'll leave ``p`` randomly chosen samples to the test dataset and the rest to train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814385d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Model: KNN3\n",
      "Accuracy=0.78 | Precision=0.84 | Recall=0.88 | F1 Score=0.86\n",
      "----------------------------------------\n",
      "Model: KNN5\n",
      "Accuracy=0.77 | Precision=0.82 | Recall=0.90 | F1 Score=0.86\n",
      "----------------------------------------\n",
      "Model: DecisionTree\n",
      "Accuracy=0.71 | Precision=0.82 | Recall=0.80 | F1 Score=0.81\n",
      "----------------------------------------\n",
      "Model: RandomForest\n",
      "Accuracy=0.72 | Precision=0.82 | Recall=0.82 | F1 Score=0.82\n",
      "----------------------------------------\n",
      "\n",
      "KNN3:\n",
      "                    Actual Positive  Actual Negative\n",
      "Predicted Positive              542              103\n",
      "Predicted Negative               76               79\n",
      "\n",
      "\n",
      "KNN5:\n",
      "                    Actual Positive  Actual Negative\n",
      "Predicted Positive              558              126\n",
      "Predicted Negative               60               56\n",
      "\n",
      "\n",
      "DecisionTree:\n",
      "                    Actual Positive  Actual Negative\n",
      "Predicted Positive              495              109\n",
      "Predicted Negative              123               73\n",
      "\n",
      "\n",
      "RandomForest:\n",
      "                    Actual Positive  Actual Negative\n",
      "Predicted Positive              505              112\n",
      "Predicted Negative              113               70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 8  # number of samples to leave out in each iteration\n",
    "N = 100  # number of iterations\n",
    "\n",
    "TEST_SIZE = p / data.shape[0]\n",
    "\n",
    "for _ in range(N):\n",
    "    # split data into random train and test sets\n",
    "    X_train, y_train, X_test, y_test = split_data(data, 'Cardiomegaly', test_size=TEST_SIZE)\n",
    "\n",
    "    # fit models\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate models\n",
    "    eval_metrics = [model.evaluate(X_test, y_test) for model in models]\n",
    "\n",
    "    # clear models for next iteration\n",
    "    for model in models:\n",
    "        model.clear()\n",
    "\n",
    "# print evaluation results\n",
    "print(\"-\" * 40)\n",
    "for model_name, summary, _ in eval_metrics:\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(summary)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# print confusion matrices\n",
    "for model_name, _, conf_matrix in eval_metrics:\n",
    "    print(f\"\\n{model_name}:\\n{conf_matrix}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
